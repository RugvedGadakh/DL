# DL


https://drive.google.com/drive/folders/1WgpjZEXUCqxoTy4RBWjF6ITdIQqdq0Z8

Here’s a quick overview of these key topics:

Autoencoder

	•	Definition: An autoencoder is a type of neural network used for unsupervised learning, typically for data compression and feature extraction. It consists of two main parts: an encoder and a decoder.
	•	Function: The encoder compresses the input into a lower-dimensional representation (latent space), and the decoder reconstructs it back to the original form.
	•	Applications: Used in anomaly detection, image denoising, and dimensionality reduction.

Encoder/Decoder

	•	Definition: In the context of neural networks, the encoder/decoder architecture is used to transform input data into a compact, meaningful representation (encoding) and then reconstruct it or produce an output (decoding).
	•	Applications: Widely used in tasks like language translation, text generation, and image-to-image translation.

Anomaly Detection

	•	Definition: Anomaly detection identifies data points, patterns, or observations that differ significantly from the expected normal patterns.
	•	Use with Autoencoders: Autoencoders can be trained on normal data; then, during inference, high reconstruction error can signal an anomaly.

NLP (Natural Language Processing)

	•	Definition: NLP enables computers to understand, interpret, and generate human language.
	•	Applications: Includes sentiment analysis, machine translation, chatbots, and text summarization.

Word2Vec

	•	Definition: Word2Vec is a neural network model that generates dense vector embeddings for words, capturing semantic relationships.
	•	Models: It has two main architectures: CBOW (Continuous Bag of Words) and Skip-gram.

CBOW Architecture

	•	Definition: CBOW (Continuous Bag of Words) predicts a target word based on surrounding context words. It’s one of the architectures used in Word2Vec.
	•	Purpose: It creates embeddings by averaging context words, capturing semantic meaning and relationships.

Tokenizer

	•	Definition: A tokenizer splits text into individual units, like words, subwords, or characters, for NLP processing.
	•	Types: Includes word tokenization, subword tokenization (e.g., Byte Pair Encoding), and character-level tokenization.

TensorFlow

	•	Definition: TensorFlow is an open-source deep learning framework developed by Google, popular for building and deploying machine learning models.
	•	Features: Provides a flexible ecosystem for model building, training, and deployment across devices.

Keras

	•	Definition: Keras is a high-level neural network API integrated with TensorFlow, designed for easy and fast experimentation.
	•	Use in TensorFlow: Keras allows for a user-friendly interface to TensorFlow’s capabilities, making model building more intuitive with fewer lines of code.

These concepts are foundational in machine learning and NLP, providing the tools for building, training, and deploying models in various applications.
